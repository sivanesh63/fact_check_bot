

# ğŸ•µï¸â€â™‚ï¸ AI Fact-Checker

A modular, LLM-powered fact-checking bot that takes a claim, verifies it using online sources, and returns a synthesized, evidence-based answer.

---

## ğŸ“‚ Project Structure

project-root/
â”œâ”€â”€ config/
â”‚ â”œâ”€â”€ settings.py # Centralized configuration
â”‚ â””â”€â”€ prompts.yaml # Prompt templates & examples
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ fact_checker.py # Core fact-checking pipeline
â”‚ â”œâ”€â”€ prompt_chains.py # LLM prompt chaining logic
â”‚ â”œâ”€â”€ search_tools.py # Evidence retrieval & web search
â”‚ â”œâ”€â”€ utils.py # Logging, cleaning, caching, helpers
â”‚ â””â”€â”€ ui/
â”‚ â”œâ”€â”€ cli.py # Command-line interface
â”‚ â”œâ”€â”€ streamlit_app.py
â”‚ â””â”€â”€ gradio_app.py
â”œâ”€â”€ tests/
â”‚ â”œâ”€â”€ test_fact_checker.py
â”‚ â””â”€â”€ test_search_tools.py
â”œâ”€â”€ examples/
â”‚ â”œâ”€â”€ example_queries.txt
â”‚ â””â”€â”€ demo_notebook.ipynb
â”œâ”€â”€ data/ # Optional: cached evidence / embeddings
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README.md



## ğŸš€ Setup & Installation

### **1. Project Setup**
```bash
# Clone the repository
git clone https://github.com/yourusername/fact-checker.git
cd fact-checker

# Create a virtual environment
python -m venv venv
venv\Scripts\activate       # Windows
# or
source venv/bin/activate    # Linux/Mac
2. Install Dependencies
bash
Copy
Edit
pip install -r requirements.txt
3. Environment Variables
Copy .env.example to .env

Add API keys for:

OpenAI

DuckDuckGo / NewsAPI / SerpAPI

Any other services you integrate

Example:

env
Copy
Edit
OPENAI_API_KEY=your_key_here
NEWS_API_KEY=your_key_here

âš™ï¸ Configuration
All configurable parameters are stored in:

config/settings.py â†’ API keys, model parameters, search settings

config/prompts.yaml â†’ Prompt templates, few-shot examples

This ensures all modules read from a single source of truth.

ğŸ§  Core Workflow
Main process (in src/fact_checker.py):

Accepts a claim

Generates an initial LLM response

Extracts assumptions

Retrieves evidence from the web

Synthesizes a final, evidence-backed answer

ğŸ”— Prompt Chaining
src/prompt_chains.py defines the sequence:

Initial Response

Assumption Extraction

Verification

Evidence Synthesis

Final Answer

Prompts are loaded from config/prompts.yaml.

ğŸŒ Evidence Retrieval
src/search_tools.py handles:

DuckDuckGo Search API

NewsAPI / SerpAPI integration

Error handling & rate-limiting

Returning top snippets and URLs

ğŸ›  Utilities
src/utils.py provides:

Logging helpers

Text cleaning functions

Query caching

Output formatting

ğŸ–¥ User Interfaces
CLI (src/ui/cli.py) â€“ Quick local testing

Streamlit (src/ui/streamlit_app.py) â€“ Interactive web app

Gradio (src/ui/gradio_app.py) â€“ Lightweight demo interface

âœ… Testing
Run with pytest or unittest:

bash
Copy
Edit
pytest tests/
ğŸ“Š Examples & Demo
examples/example_queries.txt â€“ Sample claims

examples/demo_notebook.ipynb â€“ Interactive notebook demo

ğŸ’¾ Optional: Database / Knowledge Storage
data/knowledge_base.db â€“ Store verified claims & evidence

data/embeddings/ â€“ Store semantic search vectors for fast lookup

ğŸ”„ Recommended Development Flow
Setup project structure & virtual environment

Add configuration files & API keys

Implement core logic (fact_checker.py)

Add prompt chaining (prompt_chains.py)

Integrate web search (search_tools.py)

Create utility functions (utils.py)

Build CLI interface

Add Streamlit / Gradio UI

Write unit tests & run examples

Optionally, add caching & vector embeddings